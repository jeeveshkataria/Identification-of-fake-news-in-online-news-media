{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalData = pd.read_csv('../datasets/nela10.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop all columns except title and reliability(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalData = totalData.drop(['id','date','source','content','author','url','published','published_utc','collection_utc'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How it looks like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>Reliability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who is Stacey Abrams, the Democrat who will re...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ban government shutdowns? Some Republicans and...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Democrats renew push for equal pay for equal work</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump attacks intel chiefs after they contradi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Border security battle begins as Congress grap...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57152</th>\n",
       "      <td>Hong Kong Officer Faces Death Threats After Fi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57153</th>\n",
       "      <td>Enough \"Quid Pro Quo\" Gaslighting!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57154</th>\n",
       "      <td>\"Born For This? I Don't Think So\" - Trump Mock...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57155</th>\n",
       "      <td>How Iran Used Google To Disrupt 5% Of Global O...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57156</th>\n",
       "      <td>Malaysia Rejects Goldman's Offer Of \"Less Than...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57157 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  Reliability\n",
       "0      Who is Stacey Abrams, the Democrat who will re...            0\n",
       "1      Ban government shutdowns? Some Republicans and...            0\n",
       "2      Democrats renew push for equal pay for equal work            0\n",
       "3      Trump attacks intel chiefs after they contradi...            0\n",
       "4      Border security battle begins as Congress grap...            0\n",
       "...                                                  ...          ...\n",
       "57152  Hong Kong Officer Faces Death Threats After Fi...            2\n",
       "57153                 Enough \"Quid Pro Quo\" Gaslighting!            2\n",
       "57154  \"Born For This? I Don't Think So\" - Trump Mock...            2\n",
       "57155  How Iran Used Google To Disrupt 5% Of Global O...            2\n",
       "57156  Malaysia Rejects Goldman's Offer Of \"Less Than...            2\n",
       "\n",
       "[57157 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check  if label=1(mixed) exists "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalData.Reliability.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalData.title=totalData.title.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalData = totalData.reset_index(drop=True)\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = []\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
    "#    text = re.sub(r'\\W+', '', text)\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text\n",
    "    return text\n",
    "totalData.title = totalData.title.apply(clean_text)\n",
    "totalData.title = totalData.title.str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test train split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and validation datasets \n",
    "from sklearn.model_selection import train_test_split\n",
    "# train_x, valid_x, train_y, valid_y = model_selection.train_test_split(train['tweet'], train['label'])\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(totalData['title'], totalData['Reliability'], test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop Unigram and Bigram Tf-Idf feature vectors from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unigram level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=None)\n",
    "tfidf_vect.fit(totalData['title'])\n",
    "xtrain_tfidf_unigram =  tfidf_vect.transform(train_x)\n",
    "xvalid_tfidf_unigram =  tfidf_vect.transform(valid_x)\n",
    "\n",
    "# bigram level tf-idf (bigram in this case)\n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,2), max_features=None)\n",
    "tfidf_vect_ngram.fit(totalData['title'])\n",
    "xtrain_tfidf_bigram =  tfidf_vect_ngram.transform(train_x)\n",
    "xvalid_tfidf_bigram =  tfidf_vect_ngram.transform(valid_x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label,  feature_vector_valid, valid_y,is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "    \n",
    "    #print(\"In Validation Data\",metrics.accuracy_score(predictions, valid_y))\n",
    "    print(\"f1 score: \",f1_score(valid_y,predictions,average='weighted'))        \n",
    "    return metrics.accuracy_score(valid_y,predictions)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Line Model Used\n",
    "## 1. Naive Bayes\n",
    "## 2. Linear Classifier\n",
    "## 3. Bagging\n",
    "## 4. Boosting\n",
    "## 5. SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Naive Bayes Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Unigram Tf-IDF features vectors using Naive Bayes\n",
      "f1 score:  0.7113740893743468\n",
      "Accuracy:  0.7870013995801259\n",
      "For Bigram Tf-IDF features vectors using Naive Bayes\n",
      "f1 score:  0.699537036800892\n",
      "Accuracy:  0.783852344296711\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes on Word Level TF IDF Vectors\n",
    "print(\"For Unigram Tf-IDF features vectors using Naive Bayes\")\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_unigram, train_y, xvalid_tfidf_unigram, valid_y)\n",
    "print (\"Accuracy: \", accuracy)\n",
    "\n",
    "# Naive Bayes on Ngram Level TF IDF Vectors\n",
    "print(\"For Bigram Tf-IDF features vectors using Naive Bayes\")\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_bigram, train_y, xvalid_tfidf_bigram, valid_y)\n",
    "print (\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Unigram TF-Idf feature vectors using Logistic Regression\n",
      "f1 score:  0.7882306617831591\n",
      "accuracy:  0.8206787963610916\n",
      "For Bigram TF-Idf feature vectors using Logistic Regression\n",
      "f1 score:  0.6923977487925838\n",
      "Accuracy:  0.7804408677396781\n"
     ]
    }
   ],
   "source": [
    "# Linear Classifier on Word Level TF IDF Vectors\n",
    "print(\"For Unigram TF-Idf feature vectors using Logistic Regression\")\n",
    "accuracy = train_model(linear_model.LogisticRegression(max_iter=500), xtrain_tfidf_unigram, train_y, xvalid_tfidf_unigram, valid_y)\n",
    "print(\"accuracy: \", accuracy)\n",
    "\n",
    "# Linear Classifier on Ngram Level TF IDF Vectors\n",
    "print(\"For Bigram TF-Idf feature vectors using Logistic Regression\")\n",
    "accuracy = train_model(linear_model.LogisticRegression(max_iter=500),  xtrain_tfidf_bigram, train_y, xvalid_tfidf_bigram, valid_y)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Unigram Tf-Idf feature vectors using Random Forest Classifier\n",
      "f1 score:  0.7945991992559391\n",
      "Accuracy:  0.8280265920223933\n",
      "For Bigram Tf-Idf feature vectors using Random Forest Classifier\n",
      "f1 score:  0.7125370023304538\n",
      "Accuracy:  0.7032015395381386\n"
     ]
    }
   ],
   "source": [
    "# RF on Word Level TF IDF Vectors\n",
    "print(\"For Unigram Tf-Idf feature vectors using Random Forest Classifier\")\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf_unigram, train_y, xvalid_tfidf_unigram, valid_y)\n",
    "print (\"Accuracy: \", accuracy)\n",
    "\n",
    "# RF on ngram Level TF IDF Vectors\n",
    "print(\"For Bigram Tf-Idf feature vectors using Random Forest Classifier\")\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf_bigram, train_y, xvalid_tfidf_bigram, valid_y)\n",
    "print (\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Unigram Tf-Idf feature vectors using Extreme Gradient Boosting\n",
      "f1 score:  0.7780950529194122\n",
      "Accuracy:  0.8152554233729881\n",
      "For Bigram Tf-Idf feature vectors using Extreme Gradient Boosting\n",
      "f1 score:  0.7121169688114273\n",
      "Accuracy:  0.7857767669699091\n"
     ]
    }
   ],
   "source": [
    "print(\"For Unigram Tf-Idf feature vectors using Extreme Gradient Boosting\")\n",
    "# Extereme Gradient Boosting on Word Level TF IDF Vectors\n",
    "accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf_unigram.tocsc(), train_y, xvalid_tfidf_unigram.tocsc(), valid_y)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "# Extereme Gradient Boosting on ngram Level TF IDF Vectors\n",
    "print(\"For Bigram Tf-Idf feature vectors using Extreme Gradient Boosting\")\n",
    "accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf_bigram.tocsc(), train_y, xvalid_tfidf_bigram.tocsc(), valid_y)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Unigram Tf-Idf feature vectors using SVM\n",
      "f1 score:  0.8012498224867763\n",
      "Accuracy:  0.8313505948215535\n",
      "For Bigram Tf-Idf feature vectors using SVM\n",
      "f1 score:  0.7279851890373011\n",
      "Accuracy:  0.7967984604618614\n"
     ]
    }
   ],
   "source": [
    "print(\"For Unigram Tf-Idf feature vectors using SVM\")\n",
    "#SVM Model on Unigram TF-IDF\n",
    "accuracy = train_model(svm.SVC(), xtrain_tfidf_unigram.tocsc(), train_y, xvalid_tfidf_unigram.tocsc(), valid_y)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "# SVM Model on Bigram TF-IDF\n",
    "print(\"For Bigram Tf-Idf feature vectors using SVM\")\n",
    "accuracy = train_model(svm.SVC(), xtrain_tfidf_bigram.tocsc(), train_y, xvalid_tfidf_bigram.tocsc(), valid_y)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
