{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-23T06:29:50.909690Z",
     "iopub.status.busy": "2020-10-23T06:29:50.909365Z",
     "iopub.status.idle": "2020-10-23T06:29:57.518358Z",
     "shell.execute_reply": "2020-10-23T06:29:57.517822Z",
     "shell.execute_reply.started": "2020-10-23T06:29:50.909601Z"
    }
   },
   "outputs": [],
   "source": [
    "# Insert code here.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm, neighbors\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# sent_encoder = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-23T06:29:57.519391Z",
     "iopub.status.busy": "2020-10-23T06:29:57.519228Z",
     "iopub.status.idle": "2020-10-23T06:30:00.548758Z",
     "shell.execute_reply": "2020-10-23T06:30:00.548121Z",
     "shell.execute_reply.started": "2020-10-23T06:29:57.519366Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 GPU(s) available.\n",
      "We will use the GPU: GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-23T06:30:00.550422Z",
     "iopub.status.busy": "2020-10-23T06:30:00.550249Z",
     "iopub.status.idle": "2020-10-23T06:30:00.574946Z",
     "shell.execute_reply": "2020-10-23T06:30:00.574469Z",
     "shell.execute_reply.started": "2020-10-23T06:30:00.550399Z"
    }
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = '../datasets/nela-gt/nela10.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-23T06:30:00.576068Z",
     "iopub.status.busy": "2020-10-23T06:30:00.575901Z",
     "iopub.status.idle": "2020-10-23T06:30:02.245811Z",
     "shell.execute_reply": "2020-10-23T06:30:02.245279Z",
     "shell.execute_reply.started": "2020-10-23T06:30:00.576048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences: 57,157\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>author</th>\n",
       "      <th>url</th>\n",
       "      <th>published</th>\n",
       "      <th>published_utc</th>\n",
       "      <th>collection_utc</th>\n",
       "      <th>Reliability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23566</th>\n",
       "      <td>thedailybeast--2019-01-17--Jimmy Kimmel Gives ...</td>\n",
       "      <td>2019-01-17</td>\n",
       "      <td>thedailybeast</td>\n",
       "      <td>Jimmy Kimmel Gives Trump a Government Shutdown...</td>\n",
       "      <td>Jimmy Kimmel has had it with the government sh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://feedproxy.google.com/~r/thedailybeast/a...</td>\n",
       "      <td>2019-01-17 06:06:11+00:00</td>\n",
       "      <td>1547723171</td>\n",
       "      <td>1567551968</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22442</th>\n",
       "      <td>tass--2019-09-16--Attacks on Saudi Aramco will...</td>\n",
       "      <td>2019-09-16</td>\n",
       "      <td>tass</td>\n",
       "      <td>Attacks on Saudi Aramco will not cause oil sho...</td>\n",
       "      <td>MOSCOW, September 16. /TASS/. The world will n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://tass.com/world/1078404</td>\n",
       "      <td>2019-09-16 18:58:18+00:00</td>\n",
       "      <td>1568674698</td>\n",
       "      <td>1569330188</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16960</th>\n",
       "      <td>realclearpolitics--2019-07-24--Iran The Case A...</td>\n",
       "      <td>2019-07-24</td>\n",
       "      <td>realclearpolitics</td>\n",
       "      <td>Iran: The Case Against War</td>\n",
       "      <td>The similarities between the current situation...</td>\n",
       "      <td>&lt;a href=\"https://www.realclearpolitics.com/aut...</td>\n",
       "      <td>https://www.realclearpolitics.com/2019/07/24/i...</td>\n",
       "      <td>2019-07-24 18:29:23+00:00</td>\n",
       "      <td>1564007363</td>\n",
       "      <td>1567535918</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36742</th>\n",
       "      <td>theseattletimes--2019-07-06--LA detective char...</td>\n",
       "      <td>2019-07-06</td>\n",
       "      <td>theseattletimes</td>\n",
       "      <td>LA detective charged with taping 37 men in bal...</td>\n",
       "      <td>ANAHEIM, Calif. (AP) — A Los Angeles police de...</td>\n",
       "      <td>The Associated Press</td>\n",
       "      <td>https://www.seattletimes.com/nation-world/nati...</td>\n",
       "      <td>2019-07-06 01:42:46+00:00</td>\n",
       "      <td>1562391766</td>\n",
       "      <td>1567536699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29528</th>\n",
       "      <td>thehuffingtonpost--2019-09-30--Jeff Flake To G...</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>thehuffingtonpost</td>\n",
       "      <td>Jeff Flake To GOP: Save Your Souls And Stand A...</td>\n",
       "      <td>Former GOP Sen. Jeff Flake (Ariz.) has a grim ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.huffpost.com/entry/jeff-flake-repu...</td>\n",
       "      <td>2019-09-30 18:23:16+00:00</td>\n",
       "      <td>1569882196</td>\n",
       "      <td>1570221911</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>aljazeera--2019-03-30--New round of power cuts...</td>\n",
       "      <td>2019-03-30</td>\n",
       "      <td>aljazeera</td>\n",
       "      <td>New round of power cuts hits major cities in V...</td>\n",
       "      <td>Caracas and other major Venezuelan cities were...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.aljazeera.com/news/2019/03/power-c...</td>\n",
       "      <td>2019-03-30 06:56:36+00:00</td>\n",
       "      <td>1553943396</td>\n",
       "      <td>1567544683</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8419</th>\n",
       "      <td>eveningstandard--2019-01-17--Anthony Hilton Ac...</td>\n",
       "      <td>2019-01-17</td>\n",
       "      <td>eveningstandard</td>\n",
       "      <td>Anthony Hilton: Active fund managers have aban...</td>\n",
       "      <td>The fund management industry produces the wron...</td>\n",
       "      <td>Anthony Hilton</td>\n",
       "      <td>https://www.standard.co.uk/business/anthony-hi...</td>\n",
       "      <td>2019-01-17 14:52:00+00:00</td>\n",
       "      <td>1547754720</td>\n",
       "      <td>1567552011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49648</th>\n",
       "      <td>naturalnews--2019-09-30--VIDEO Antifa proteste...</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>naturalnews</td>\n",
       "      <td>VIDEO: Antifa protesters scream at, block elde...</td>\n",
       "      <td>(Natural News) A video out of Hamilton, Ontari...</td>\n",
       "      <td>News Editors</td>\n",
       "      <td>http://www.naturalnews.com/2019-09-30-video-an...</td>\n",
       "      <td>2019-09-30 19:23:50+00:00</td>\n",
       "      <td>1569885830</td>\n",
       "      <td>1570221909</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34057</th>\n",
       "      <td>theindependent--2019-09-16--10 face powders th...</td>\n",
       "      <td>2019-09-16</td>\n",
       "      <td>theindependent</td>\n",
       "      <td>10 face powders that brighten, mattify and giv...</td>\n",
       "      <td>Everyone has their holy grail foundation, but ...</td>\n",
       "      <td>Chloë James</td>\n",
       "      <td>https://www.independent.co.uk/extras/indybest/...</td>\n",
       "      <td>2019-09-16 14:58:58+00:00</td>\n",
       "      <td>1568660338</td>\n",
       "      <td>1569330191</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37770</th>\n",
       "      <td>thetelegraph--2019-05-26--Beth Mead can be rea...</td>\n",
       "      <td>2019-05-26</td>\n",
       "      <td>thetelegraph</td>\n",
       "      <td>Beth Mead can be real threat for England at Wo...</td>\n",
       "      <td>The England head coach Phil Neville has said A...</td>\n",
       "      <td>Katie Whyatt</td>\n",
       "      <td>https://www.telegraph.co.uk/world-cup/2019/05/...</td>\n",
       "      <td>2019-05-26 21:30:00+00:00</td>\n",
       "      <td>1558920600</td>\n",
       "      <td>1567540163</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      id        date  \\\n",
       "23566  thedailybeast--2019-01-17--Jimmy Kimmel Gives ...  2019-01-17   \n",
       "22442  tass--2019-09-16--Attacks on Saudi Aramco will...  2019-09-16   \n",
       "16960  realclearpolitics--2019-07-24--Iran The Case A...  2019-07-24   \n",
       "36742  theseattletimes--2019-07-06--LA detective char...  2019-07-06   \n",
       "29528  thehuffingtonpost--2019-09-30--Jeff Flake To G...  2019-09-30   \n",
       "832    aljazeera--2019-03-30--New round of power cuts...  2019-03-30   \n",
       "8419   eveningstandard--2019-01-17--Anthony Hilton Ac...  2019-01-17   \n",
       "49648  naturalnews--2019-09-30--VIDEO Antifa proteste...  2019-09-30   \n",
       "34057  theindependent--2019-09-16--10 face powders th...  2019-09-16   \n",
       "37770  thetelegraph--2019-05-26--Beth Mead can be rea...  2019-05-26   \n",
       "\n",
       "                  source                                              title  \\\n",
       "23566      thedailybeast  Jimmy Kimmel Gives Trump a Government Shutdown...   \n",
       "22442               tass  Attacks on Saudi Aramco will not cause oil sho...   \n",
       "16960  realclearpolitics                         Iran: The Case Against War   \n",
       "36742    theseattletimes  LA detective charged with taping 37 men in bal...   \n",
       "29528  thehuffingtonpost  Jeff Flake To GOP: Save Your Souls And Stand A...   \n",
       "832            aljazeera  New round of power cuts hits major cities in V...   \n",
       "8419     eveningstandard  Anthony Hilton: Active fund managers have aban...   \n",
       "49648        naturalnews  VIDEO: Antifa protesters scream at, block elde...   \n",
       "34057     theindependent  10 face powders that brighten, mattify and giv...   \n",
       "37770       thetelegraph  Beth Mead can be real threat for England at Wo...   \n",
       "\n",
       "                                                 content  \\\n",
       "23566  Jimmy Kimmel has had it with the government sh...   \n",
       "22442  MOSCOW, September 16. /TASS/. The world will n...   \n",
       "16960  The similarities between the current situation...   \n",
       "36742  ANAHEIM, Calif. (AP) — A Los Angeles police de...   \n",
       "29528  Former GOP Sen. Jeff Flake (Ariz.) has a grim ...   \n",
       "832    Caracas and other major Venezuelan cities were...   \n",
       "8419   The fund management industry produces the wron...   \n",
       "49648  (Natural News) A video out of Hamilton, Ontari...   \n",
       "34057  Everyone has their holy grail foundation, but ...   \n",
       "37770  The England head coach Phil Neville has said A...   \n",
       "\n",
       "                                                  author  \\\n",
       "23566                                                NaN   \n",
       "22442                                                NaN   \n",
       "16960  <a href=\"https://www.realclearpolitics.com/aut...   \n",
       "36742                               The Associated Press   \n",
       "29528                                                NaN   \n",
       "832                                                  NaN   \n",
       "8419                                      Anthony Hilton   \n",
       "49648                                       News Editors   \n",
       "34057                                        Chloë James   \n",
       "37770                                       Katie Whyatt   \n",
       "\n",
       "                                                     url  \\\n",
       "23566  http://feedproxy.google.com/~r/thedailybeast/a...   \n",
       "22442                     https://tass.com/world/1078404   \n",
       "16960  https://www.realclearpolitics.com/2019/07/24/i...   \n",
       "36742  https://www.seattletimes.com/nation-world/nati...   \n",
       "29528  https://www.huffpost.com/entry/jeff-flake-repu...   \n",
       "832    https://www.aljazeera.com/news/2019/03/power-c...   \n",
       "8419   https://www.standard.co.uk/business/anthony-hi...   \n",
       "49648  http://www.naturalnews.com/2019-09-30-video-an...   \n",
       "34057  https://www.independent.co.uk/extras/indybest/...   \n",
       "37770  https://www.telegraph.co.uk/world-cup/2019/05/...   \n",
       "\n",
       "                       published  published_utc  collection_utc  Reliability  \n",
       "23566  2019-01-17 06:06:11+00:00     1547723171      1567551968            0  \n",
       "22442  2019-09-16 18:58:18+00:00     1568674698      1569330188            0  \n",
       "16960  2019-07-24 18:29:23+00:00     1564007363      1567535918            0  \n",
       "36742  2019-07-06 01:42:46+00:00     1562391766      1567536699            0  \n",
       "29528  2019-09-30 18:23:16+00:00     1569882196      1570221911            0  \n",
       "832    2019-03-30 06:56:36+00:00     1553943396      1567544683            0  \n",
       "8419   2019-01-17 14:52:00+00:00     1547754720      1567552011            0  \n",
       "49648  2019-09-30 19:23:50+00:00     1569885830      1570221909            2  \n",
       "34057  2019-09-16 14:58:58+00:00     1568660338      1569330191            0  \n",
       "37770  2019-05-26 21:30:00+00:00     1558920600      1567540163            0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATASET_PATH)\n",
    "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-23T06:30:02.246711Z",
     "iopub.status.busy": "2020-10-23T06:30:02.246564Z",
     "iopub.status.idle": "2020-10-23T06:30:02.249583Z",
     "shell.execute_reply": "2020-10-23T06:30:02.249036Z",
     "shell.execute_reply.started": "2020-10-23T06:30:02.246691Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_words(text):\n",
    "    try:\n",
    "        return len(text.split())\n",
    "    except:\n",
    "        print(text)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-23T06:30:02.250502Z",
     "iopub.status.busy": "2020-10-23T06:30:02.250356Z",
     "iopub.status.idle": "2020-10-23T06:30:02.622622Z",
     "shell.execute_reply": "2020-10-23T06:30:02.621883Z",
     "shell.execute_reply.started": "2020-10-23T06:30:02.250479Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = []\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = str(text)\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
    "#    text = re.sub(r'\\W+', '', text)\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text\n",
    "    return text\n",
    "df['title'] = df['title'].apply(clean_text)\n",
    "df['title'] = df['title'].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-23T06:30:02.623575Z",
     "iopub.status.busy": "2020-10-23T06:30:02.623426Z",
     "iopub.status.idle": "2020-10-23T06:30:02.673838Z",
     "shell.execute_reply": "2020-10-23T06:30:02.673409Z",
     "shell.execute_reply.started": "2020-10-23T06:30:02.623556Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title'].apply(count_words).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-23T06:30:02.674690Z",
     "iopub.status.busy": "2020-10-23T06:30:02.674549Z",
     "iopub.status.idle": "2020-10-23T06:30:02.696146Z",
     "shell.execute_reply": "2020-10-23T06:30:02.695660Z",
     "shell.execute_reply.started": "2020-10-23T06:30:02.674672Z"
    }
   },
   "outputs": [],
   "source": [
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(df['title'], df['Reliability'], test_size=0.2, stratify=df['Reliability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-23T06:30:02.697410Z",
     "iopub.status.busy": "2020-10-23T06:30:02.697252Z",
     "iopub.status.idle": "2020-10-23T06:30:02.699888Z",
     "shell.execute_reply": "2020-10-23T06:30:02.699429Z",
     "shell.execute_reply.started": "2020-10-23T06:30:02.697392Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 40\n",
    "posts = train_x.values\n",
    "categories = train_y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-23T06:31:11.432527Z",
     "iopub.status.busy": "2020-10-23T06:31:11.432336Z",
     "iopub.status.idle": "2020-10-23T06:31:11.440023Z",
     "shell.execute_reply": "2020-10-23T06:31:11.439018Z",
     "shell.execute_reply.started": "2020-10-23T06:31:11.432504Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2339, 6830, 2287, 5807, 2102, 2022, 6668,  102,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dict = tokenizer.encode_plus(\n",
    "                        posts[0],                      # Sentence to encode.\n",
    "                        truncation=True,\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = MAX_LENGTH,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "encoded_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-23T06:31:28.281598Z",
     "iopub.status.busy": "2020-10-23T06:31:28.281377Z",
     "iopub.status.idle": "2020-10-23T06:31:42.837678Z",
     "shell.execute_reply": "2020-10-23T06:31:42.836572Z",
     "shell.execute_reply.started": "2020-10-23T06:31:28.281573Z"
    }
   },
   "outputs": [],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in posts:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        truncation=True,\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = MAX_LENGTH,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-23T06:31:57.516628Z",
     "iopub.status.busy": "2020-10-23T06:31:57.516338Z",
     "iopub.status.idle": "2020-10-23T06:31:57.526647Z",
     "shell.execute_reply": "2020-10-23T06:31:57.525779Z",
     "shell.execute_reply.started": "2020-10-23T06:31:57.516596Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40,009 training samples\n",
      "5,716 validation samples\n"
     ]
    }
   ],
   "source": [
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "train_size = int(0.875 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# Divide the dataset by randomly selecting samples.\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-23T06:32:19.479620Z",
     "iopub.status.busy": "2020-10-23T06:32:19.479359Z",
     "iopub.status.idle": "2020-10-23T06:32:19.484918Z",
     "shell.execute_reply": "2020-10-23T06:32:19.484345Z",
     "shell.execute_reply.started": "2020-10-23T06:32:19.479582Z"
    }
   },
   "outputs": [],
   "source": [
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "# size of 16 or 32.\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-23T06:32:25.497582Z",
     "iopub.status.busy": "2020-10-23T06:32:25.497379Z",
     "iopub.status.idle": "2020-10-23T06:38:08.542164Z",
     "shell.execute_reply": "2020-10-23T06:38:08.541453Z",
     "shell.execute_reply.started": "2020-10-23T06:32:25.497558Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98b2c237a9b548e99091fdc1b4f8ce6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deb8d988a814462398cb145678c778ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 4, # The number of output labels--2 for binary classification.\n",
    "                    # You can increase this for multi-class tasks.\n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-23T06:38:08.543658Z",
     "iopub.status.busy": "2020-10-23T06:38:08.543494Z",
     "iopub.status.idle": "2020-10-23T06:38:08.552422Z",
     "shell.execute_reply": "2020-10-23T06:38:08.551918Z",
     "shell.execute_reply.started": "2020-10-23T06:38:08.543636Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (4, 768)\n",
      "classifier.bias                                                 (4,)\n"
     ]
    }
   ],
   "source": [
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-23T06:38:08.553602Z",
     "iopub.status.busy": "2020-10-23T06:38:08.553445Z",
     "iopub.status.idle": "2020-10-23T06:38:08.558303Z",
     "shell.execute_reply": "2020-10-23T06:38:08.557876Z",
     "shell.execute_reply.started": "2020-10-23T06:38:08.553583Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 5e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-23T06:38:08.559310Z",
     "iopub.status.busy": "2020-10-23T06:38:08.559159Z",
     "iopub.status.idle": "2020-10-23T06:38:08.565445Z",
     "shell.execute_reply": "2020-10-23T06:38:08.565004Z",
     "shell.execute_reply.started": "2020-10-23T06:38:08.559291Z"
    }
   },
   "outputs": [],
   "source": [
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = 4\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-23T06:38:08.566313Z",
     "iopub.status.busy": "2020-10-23T06:38:08.566167Z",
     "iopub.status.idle": "2020-10-23T06:38:08.572148Z",
     "shell.execute_reply": "2020-10-23T06:38:08.571693Z",
     "shell.execute_reply.started": "2020-10-23T06:38:08.566295Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-23T06:38:08.572969Z",
     "iopub.status.busy": "2020-10-23T06:38:08.572822Z",
     "iopub.status.idle": "2020-10-23T06:38:08.578819Z",
     "shell.execute_reply": "2020-10-23T06:38:08.578379Z",
     "shell.execute_reply.started": "2020-10-23T06:38:08.572950Z"
    }
   },
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-23T06:38:08.579757Z",
     "iopub.status.busy": "2020-10-23T06:38:08.579594Z",
     "iopub.status.idle": "2020-10-23T06:45:16.095531Z",
     "shell.execute_reply": "2020-10-23T06:45:16.094826Z",
     "shell.execute_reply.started": "2020-10-23T06:38:08.579738Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of  1,251.    Elapsed: 0:00:05.\n",
      "  Batch    80  of  1,251.    Elapsed: 0:00:09.\n",
      "  Batch   120  of  1,251.    Elapsed: 0:00:12.\n",
      "  Batch   160  of  1,251.    Elapsed: 0:00:16.\n",
      "  Batch   200  of  1,251.    Elapsed: 0:00:20.\n",
      "  Batch   240  of  1,251.    Elapsed: 0:00:24.\n",
      "  Batch   280  of  1,251.    Elapsed: 0:00:28.\n",
      "  Batch   320  of  1,251.    Elapsed: 0:00:32.\n",
      "  Batch   360  of  1,251.    Elapsed: 0:00:36.\n",
      "  Batch   400  of  1,251.    Elapsed: 0:00:40.\n",
      "  Batch   440  of  1,251.    Elapsed: 0:00:44.\n",
      "  Batch   480  of  1,251.    Elapsed: 0:00:48.\n",
      "  Batch   520  of  1,251.    Elapsed: 0:00:52.\n",
      "  Batch   560  of  1,251.    Elapsed: 0:00:56.\n",
      "  Batch   600  of  1,251.    Elapsed: 0:01:00.\n",
      "  Batch   640  of  1,251.    Elapsed: 0:01:04.\n",
      "  Batch   680  of  1,251.    Elapsed: 0:01:08.\n",
      "  Batch   720  of  1,251.    Elapsed: 0:01:12.\n",
      "  Batch   760  of  1,251.    Elapsed: 0:01:16.\n",
      "  Batch   800  of  1,251.    Elapsed: 0:01:20.\n",
      "  Batch   840  of  1,251.    Elapsed: 0:01:24.\n",
      "  Batch   880  of  1,251.    Elapsed: 0:01:28.\n",
      "  Batch   920  of  1,251.    Elapsed: 0:01:32.\n",
      "  Batch   960  of  1,251.    Elapsed: 0:01:36.\n",
      "  Batch 1,000  of  1,251.    Elapsed: 0:01:40.\n",
      "  Batch 1,040  of  1,251.    Elapsed: 0:01:44.\n",
      "  Batch 1,080  of  1,251.    Elapsed: 0:01:48.\n",
      "  Batch 1,120  of  1,251.    Elapsed: 0:01:52.\n",
      "  Batch 1,160  of  1,251.    Elapsed: 0:01:56.\n",
      "  Batch 1,200  of  1,251.    Elapsed: 0:02:00.\n",
      "  Batch 1,240  of  1,251.    Elapsed: 0:02:04.\n",
      "\n",
      "  Average training loss: 0.39\n",
      "  Training epcoh took: 0:02:05\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.84\n",
      "  Validation Loss: 0.35\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of  1,251.    Elapsed: 0:00:04.\n",
      "  Batch    80  of  1,251.    Elapsed: 0:00:08.\n",
      "  Batch   120  of  1,251.    Elapsed: 0:00:12.\n",
      "  Batch   160  of  1,251.    Elapsed: 0:00:16.\n",
      "  Batch   200  of  1,251.    Elapsed: 0:00:20.\n",
      "  Batch   240  of  1,251.    Elapsed: 0:00:24.\n",
      "  Batch   280  of  1,251.    Elapsed: 0:00:28.\n",
      "  Batch   320  of  1,251.    Elapsed: 0:00:32.\n",
      "  Batch   360  of  1,251.    Elapsed: 0:00:36.\n",
      "  Batch   400  of  1,251.    Elapsed: 0:00:40.\n",
      "  Batch   440  of  1,251.    Elapsed: 0:00:44.\n",
      "  Batch   480  of  1,251.    Elapsed: 0:00:49.\n",
      "  Batch   520  of  1,251.    Elapsed: 0:00:53.\n",
      "  Batch   560  of  1,251.    Elapsed: 0:00:57.\n",
      "  Batch   600  of  1,251.    Elapsed: 0:01:01.\n",
      "  Batch   640  of  1,251.    Elapsed: 0:01:05.\n",
      "  Batch   680  of  1,251.    Elapsed: 0:01:09.\n",
      "  Batch   720  of  1,251.    Elapsed: 0:01:13.\n",
      "  Batch   760  of  1,251.    Elapsed: 0:01:17.\n",
      "  Batch   800  of  1,251.    Elapsed: 0:01:21.\n",
      "  Batch   840  of  1,251.    Elapsed: 0:01:25.\n",
      "  Batch   880  of  1,251.    Elapsed: 0:01:29.\n",
      "  Batch   920  of  1,251.    Elapsed: 0:01:33.\n",
      "  Batch   960  of  1,251.    Elapsed: 0:01:37.\n",
      "  Batch 1,000  of  1,251.    Elapsed: 0:01:41.\n",
      "  Batch 1,040  of  1,251.    Elapsed: 0:01:45.\n",
      "  Batch 1,080  of  1,251.    Elapsed: 0:01:49.\n",
      "  Batch 1,120  of  1,251.    Elapsed: 0:01:53.\n",
      "  Batch 1,160  of  1,251.    Elapsed: 0:01:57.\n",
      "  Batch 1,200  of  1,251.    Elapsed: 0:02:01.\n",
      "  Batch 1,240  of  1,251.    Elapsed: 0:02:06.\n",
      "\n",
      "  Average training loss: 0.24\n",
      "  Training epcoh took: 0:02:07\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.86\n",
      "  Validation Loss: 0.35\n",
      "  Validation took: 0:00:05\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " no\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of  1,251.    Elapsed: 0:00:04.\n",
      "  Batch    80  of  1,251.    Elapsed: 0:00:08.\n",
      "  Batch   120  of  1,251.    Elapsed: 0:00:12.\n",
      "  Batch   160  of  1,251.    Elapsed: 0:00:16.\n",
      "  Batch   200  of  1,251.    Elapsed: 0:00:20.\n",
      "  Batch   240  of  1,251.    Elapsed: 0:00:24.\n",
      "  Batch   280  of  1,251.    Elapsed: 0:00:28.\n",
      "  Batch   320  of  1,251.    Elapsed: 0:00:32.\n",
      "  Batch   360  of  1,251.    Elapsed: 0:00:36.\n",
      "  Batch   400  of  1,251.    Elapsed: 0:00:40.\n",
      "  Batch   440  of  1,251.    Elapsed: 0:00:44.\n",
      "  Batch   480  of  1,251.    Elapsed: 0:00:48.\n",
      "  Batch   520  of  1,251.    Elapsed: 0:00:52.\n",
      "  Batch   560  of  1,251.    Elapsed: 0:00:56.\n",
      "  Batch   600  of  1,251.    Elapsed: 0:01:00.\n",
      "  Batch   640  of  1,251.    Elapsed: 0:01:04.\n",
      "  Batch   680  of  1,251.    Elapsed: 0:01:08.\n",
      "  Batch   720  of  1,251.    Elapsed: 0:01:12.\n",
      "  Batch   760  of  1,251.    Elapsed: 0:01:16.\n",
      "  Batch   800  of  1,251.    Elapsed: 0:01:20.\n",
      "  Batch   840  of  1,251.    Elapsed: 0:01:25.\n",
      "  Batch   880  of  1,251.    Elapsed: 0:01:29.\n",
      "  Batch   920  of  1,251.    Elapsed: 0:01:33.\n",
      "  Batch   960  of  1,251.    Elapsed: 0:01:37.\n",
      "  Batch 1,000  of  1,251.    Elapsed: 0:01:41.\n",
      "  Batch 1,040  of  1,251.    Elapsed: 0:01:45.\n",
      "  Batch 1,080  of  1,251.    Elapsed: 0:01:49.\n",
      "  Batch 1,120  of  1,251.    Elapsed: 0:01:53.\n",
      "  Batch 1,160  of  1,251.    Elapsed: 0:01:57.\n",
      "  Batch 1,200  of  1,251.    Elapsed: 0:02:01.\n",
      "  Batch 1,240  of  1,251.    Elapsed: 0:02:05.\n",
      "\n",
      "  Average training loss: 0.12\n",
      "  Training epcoh took: 0:02:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.86\n",
      "  Validation Loss: 0.53\n",
      "  Validation took: 0:00:05\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete!\n",
      "Total training took 0:07:07 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "seed_val = 42\n",
    "torch.cuda.empty_cache()\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# We'll store a number of quantities such as training and validation loss, \n",
    "# validation accuracy, and timings.\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        # It returns different numbers of parameters depending on what arguments\n",
    "        # arge given and what flags are set. For our useage here, it returns\n",
    "        # the loss (because we provided labels) and the \"logits\"--the model\n",
    "        # outputs prior to activation.\n",
    "        loss, logits = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "            # values prior to applying an activation function like the softmax.\n",
    "            (loss, logits) = model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "            \n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "        \n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "    if epoch_i >= 1:\n",
    "        inp = input()\n",
    "        if inp.startswith('y'):\n",
    "            break\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
