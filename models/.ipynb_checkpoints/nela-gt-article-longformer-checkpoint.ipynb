{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-23T09:34:26.160993Z",
     "iopub.status.busy": "2020-10-23T09:34:26.160815Z",
     "iopub.status.idle": "2020-10-23T09:34:31.216039Z",
     "shell.execute_reply": "2020-10-23T09:34:31.215471Z",
     "shell.execute_reply.started": "2020-10-23T09:34:26.160946Z"
    }
   },
   "outputs": [],
   "source": [
    "# Insert code here.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm, neighbors\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# sent_encoder = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-23T09:34:31.217230Z",
     "iopub.status.busy": "2020-10-23T09:34:31.217070Z",
     "iopub.status.idle": "2020-10-23T09:34:34.272126Z",
     "shell.execute_reply": "2020-10-23T09:34:34.271404Z",
     "shell.execute_reply.started": "2020-10-23T09:34:31.217209Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 GPU(s) available.\n",
      "We will use the GPU: GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-23T09:34:34.274168Z",
     "iopub.status.busy": "2020-10-23T09:34:34.273944Z",
     "iopub.status.idle": "2020-10-23T09:34:34.464452Z",
     "shell.execute_reply": "2020-10-23T09:34:34.463980Z",
     "shell.execute_reply.started": "2020-10-23T09:34:34.274144Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Oct 23 15:04:34 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.95.01    Driver Version: 440.95.01    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:02:00.0 Off |                  N/A |\n",
      "| 35%   57C    P0    69W / 250W |     11MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:03:00.0 Off |                  N/A |\n",
      "| 30%   26C    P0    70W / 250W |     11MiB / 11019MiB |      1%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 208...  Off  | 00000000:82:00.0 Off |                  N/A |\n",
      "| 30%   25C    P0    54W / 250W |     11MiB / 11019MiB |      1%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce RTX 208...  Off  | 00000000:83:00.0 Off |                  N/A |\n",
      "| 36%   26C    P0    62W / 250W |     11MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-23T09:34:34.465788Z",
     "iopub.status.busy": "2020-10-23T09:34:34.465591Z",
     "iopub.status.idle": "2020-10-23T09:34:34.468929Z",
     "shell.execute_reply": "2020-10-23T09:34:34.468319Z",
     "shell.execute_reply.started": "2020-10-23T09:34:34.465765Z"
    }
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = '../datasets/nela-gt/nela10.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-23T09:34:34.469881Z",
     "iopub.status.busy": "2020-10-23T09:34:34.469659Z",
     "iopub.status.idle": "2020-10-23T09:34:36.146608Z",
     "shell.execute_reply": "2020-10-23T09:34:36.145982Z",
     "shell.execute_reply.started": "2020-10-23T09:34:34.469860Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences: 57,157\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>author</th>\n",
       "      <th>url</th>\n",
       "      <th>published</th>\n",
       "      <th>published_utc</th>\n",
       "      <th>collection_utc</th>\n",
       "      <th>Reliability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21604</th>\n",
       "      <td>tass--2019-02-04--Kremlin stresses only Venezu...</td>\n",
       "      <td>2019-02-04</td>\n",
       "      <td>tass</td>\n",
       "      <td>Kremlin stresses only Venezuelans themselves c...</td>\n",
       "      <td>MOSCOW, February 4. /TASS/. Moscow has labeled...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://tass.com/politics/1043139</td>\n",
       "      <td>2019-02-04 11:17:35+00:00</td>\n",
       "      <td>1549297055</td>\n",
       "      <td>1567549654</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48761</th>\n",
       "      <td>intellihub--2019-10-04--Ukraine to review inve...</td>\n",
       "      <td>2019-10-04</td>\n",
       "      <td>intellihub</td>\n",
       "      <td>Ukraine to review investigation into Biden-lin...</td>\n",
       "      <td>After a week of non-stop “bombshell” leaks abo...</td>\n",
       "      <td>Zero Hedge</td>\n",
       "      <td>https://www.intellihub.com/ukraine-to-review-i...</td>\n",
       "      <td>2019-10-04 12:13:12+00:00</td>\n",
       "      <td>1570205592</td>\n",
       "      <td>1570633618</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5577</th>\n",
       "      <td>cnbc--2019-02-04--Ocasio-Cortez and Warrens we...</td>\n",
       "      <td>2019-02-04</td>\n",
       "      <td>cnbc</td>\n",
       "      <td>Ocasio-Cortez and Warren's wealth tax plans ar...</td>\n",
       "      <td>\"I wish some economist would go and talk to th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.cnbc.com/2019/02/04/hassett-warren...</td>\n",
       "      <td>2019-02-04 13:47:00+00:00</td>\n",
       "      <td>1549306020</td>\n",
       "      <td>1567549705</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11514</th>\n",
       "      <td>france24--2019-08-12--India death toll rises t...</td>\n",
       "      <td>2019-08-12</td>\n",
       "      <td>france24</td>\n",
       "      <td>India death toll rises to 144 as floods cut of...</td>\n",
       "      <td>STR, AFP | Rescue workers carry a body as they...</td>\n",
       "      <td>NEWS WIRES</td>\n",
       "      <td>https://www.france24.com/en/20190812-india-flo...</td>\n",
       "      <td>2019-08-12 08:52:32+00:00</td>\n",
       "      <td>1565614352</td>\n",
       "      <td>1567534381</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56494</th>\n",
       "      <td>vdare--2019-09-18--A Catholic Reader Reproves ...</td>\n",
       "      <td>2019-09-18</td>\n",
       "      <td>vdare</td>\n",
       "      <td>A Catholic Reader Reproves Matthew Schmitz For...</td>\n",
       "      <td>Re: This French-Sohrab Ahmari “Debate” Won’t G...</td>\n",
       "      <td>reader@vdare.com (VDARE.com Reader)</td>\n",
       "      <td>https://vdare.com/letters/a-catholic-reader-re...</td>\n",
       "      <td>2019-09-18 01:36:59+00:00</td>\n",
       "      <td>1568785019</td>\n",
       "      <td>1569329981</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50802</th>\n",
       "      <td>newswars--2019-06-27--Don Jr Endorses Infowars...</td>\n",
       "      <td>2019-06-27</td>\n",
       "      <td>newswars</td>\n",
       "      <td>Don Jr. Endorses Infowars’ “Clown World” Parad...</td>\n",
       "      <td>Donald Trump Jr. echoed Infowars’ Democrat Deb...</td>\n",
       "      <td>Infowars.com</td>\n",
       "      <td>https://www.newswars.com/don-jr-endorses-infow...</td>\n",
       "      <td>2019-06-27 02:06:31+00:00</td>\n",
       "      <td>1561615591</td>\n",
       "      <td>1567537924</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51109</th>\n",
       "      <td>prisonplanet--2019-02-04--Politico Trump Is Ma...</td>\n",
       "      <td>2019-02-04</td>\n",
       "      <td>prisonplanet</td>\n",
       "      <td>Politico: Trump Is Making People Sick</td>\n",
       "      <td>CNN before lovemaking is not his idea of a tur...</td>\n",
       "      <td>admin</td>\n",
       "      <td>https://www.prisonplanet.com/politico-trump-is...</td>\n",
       "      <td>2019-02-04 11:26:15+00:00</td>\n",
       "      <td>1549297575</td>\n",
       "      <td>1567549732</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3972</th>\n",
       "      <td>bbcuk--2019-06-27--Ex-Army translator wants to...</td>\n",
       "      <td>2019-06-27</td>\n",
       "      <td>bbcuk</td>\n",
       "      <td>Ex-Army translator wants to swap burgers for N...</td>\n",
       "      <td>An Afghan interpreter who risked his life help...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.bbc.co.uk/news/uk-england-leiceste...</td>\n",
       "      <td>2019-06-27 14:05:23+00:00</td>\n",
       "      <td>1561658723</td>\n",
       "      <td>1567537912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12236</th>\n",
       "      <td>hotair--2019-06-27--Audio Trump accusers confi...</td>\n",
       "      <td>2019-06-27</td>\n",
       "      <td>hotair</td>\n",
       "      <td>Audio: Trump accuser’s confidants corroborate ...</td>\n",
       "      <td>The full NYT podcast is long at nearly 30 minu...</td>\n",
       "      <td>Allahpundit</td>\n",
       "      <td>https://hotair.com/archives/2019/06/27/audio-t...</td>\n",
       "      <td>2019-06-27 18:01:36+00:00</td>\n",
       "      <td>1561672896</td>\n",
       "      <td>1567537925</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13041</th>\n",
       "      <td>mcclatchydc--2019-10-08--Justice Department la...</td>\n",
       "      <td>2019-10-08</td>\n",
       "      <td>mcclatchydc</td>\n",
       "      <td>Justice Department labels Devin Nunes’ claim o...</td>\n",
       "      <td>A talking point used by some leading Republica...</td>\n",
       "      <td>&lt;p&gt;&lt;span class=\"ng_byline_name\"&gt;By Kevin G. Ha...</td>\n",
       "      <td>https://www.mcclatchydc.com/news/crime/article...</td>\n",
       "      <td>Tue, 08 Oct 2019 17:54:42 EDT</td>\n",
       "      <td>1570571682</td>\n",
       "      <td>1570842344</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      id        date  \\\n",
       "21604  tass--2019-02-04--Kremlin stresses only Venezu...  2019-02-04   \n",
       "48761  intellihub--2019-10-04--Ukraine to review inve...  2019-10-04   \n",
       "5577   cnbc--2019-02-04--Ocasio-Cortez and Warrens we...  2019-02-04   \n",
       "11514  france24--2019-08-12--India death toll rises t...  2019-08-12   \n",
       "56494  vdare--2019-09-18--A Catholic Reader Reproves ...  2019-09-18   \n",
       "50802  newswars--2019-06-27--Don Jr Endorses Infowars...  2019-06-27   \n",
       "51109  prisonplanet--2019-02-04--Politico Trump Is Ma...  2019-02-04   \n",
       "3972   bbcuk--2019-06-27--Ex-Army translator wants to...  2019-06-27   \n",
       "12236  hotair--2019-06-27--Audio Trump accusers confi...  2019-06-27   \n",
       "13041  mcclatchydc--2019-10-08--Justice Department la...  2019-10-08   \n",
       "\n",
       "             source                                              title  \\\n",
       "21604          tass  Kremlin stresses only Venezuelans themselves c...   \n",
       "48761    intellihub  Ukraine to review investigation into Biden-lin...   \n",
       "5577           cnbc  Ocasio-Cortez and Warren's wealth tax plans ar...   \n",
       "11514      france24  India death toll rises to 144 as floods cut of...   \n",
       "56494         vdare  A Catholic Reader Reproves Matthew Schmitz For...   \n",
       "50802      newswars  Don Jr. Endorses Infowars’ “Clown World” Parad...   \n",
       "51109  prisonplanet              Politico: Trump Is Making People Sick   \n",
       "3972          bbcuk  Ex-Army translator wants to swap burgers for N...   \n",
       "12236        hotair  Audio: Trump accuser’s confidants corroborate ...   \n",
       "13041   mcclatchydc  Justice Department labels Devin Nunes’ claim o...   \n",
       "\n",
       "                                                 content  \\\n",
       "21604  MOSCOW, February 4. /TASS/. Moscow has labeled...   \n",
       "48761  After a week of non-stop “bombshell” leaks abo...   \n",
       "5577   \"I wish some economist would go and talk to th...   \n",
       "11514  STR, AFP | Rescue workers carry a body as they...   \n",
       "56494  Re: This French-Sohrab Ahmari “Debate” Won’t G...   \n",
       "50802  Donald Trump Jr. echoed Infowars’ Democrat Deb...   \n",
       "51109  CNN before lovemaking is not his idea of a tur...   \n",
       "3972   An Afghan interpreter who risked his life help...   \n",
       "12236  The full NYT podcast is long at nearly 30 minu...   \n",
       "13041  A talking point used by some leading Republica...   \n",
       "\n",
       "                                                  author  \\\n",
       "21604                                                NaN   \n",
       "48761                                         Zero Hedge   \n",
       "5577                                                 NaN   \n",
       "11514                                         NEWS WIRES   \n",
       "56494                reader@vdare.com (VDARE.com Reader)   \n",
       "50802                                       Infowars.com   \n",
       "51109                                              admin   \n",
       "3972                                                 NaN   \n",
       "12236                                        Allahpundit   \n",
       "13041  <p><span class=\"ng_byline_name\">By Kevin G. Ha...   \n",
       "\n",
       "                                                     url  \\\n",
       "21604                   http://tass.com/politics/1043139   \n",
       "48761  https://www.intellihub.com/ukraine-to-review-i...   \n",
       "5577   https://www.cnbc.com/2019/02/04/hassett-warren...   \n",
       "11514  https://www.france24.com/en/20190812-india-flo...   \n",
       "56494  https://vdare.com/letters/a-catholic-reader-re...   \n",
       "50802  https://www.newswars.com/don-jr-endorses-infow...   \n",
       "51109  https://www.prisonplanet.com/politico-trump-is...   \n",
       "3972   https://www.bbc.co.uk/news/uk-england-leiceste...   \n",
       "12236  https://hotair.com/archives/2019/06/27/audio-t...   \n",
       "13041  https://www.mcclatchydc.com/news/crime/article...   \n",
       "\n",
       "                           published  published_utc  collection_utc  \\\n",
       "21604      2019-02-04 11:17:35+00:00     1549297055      1567549654   \n",
       "48761      2019-10-04 12:13:12+00:00     1570205592      1570633618   \n",
       "5577       2019-02-04 13:47:00+00:00     1549306020      1567549705   \n",
       "11514      2019-08-12 08:52:32+00:00     1565614352      1567534381   \n",
       "56494      2019-09-18 01:36:59+00:00     1568785019      1569329981   \n",
       "50802      2019-06-27 02:06:31+00:00     1561615591      1567537924   \n",
       "51109      2019-02-04 11:26:15+00:00     1549297575      1567549732   \n",
       "3972       2019-06-27 14:05:23+00:00     1561658723      1567537912   \n",
       "12236      2019-06-27 18:01:36+00:00     1561672896      1567537925   \n",
       "13041  Tue, 08 Oct 2019 17:54:42 EDT     1570571682      1570842344   \n",
       "\n",
       "       Reliability  \n",
       "21604            0  \n",
       "48761            2  \n",
       "5577             0  \n",
       "11514            0  \n",
       "56494            2  \n",
       "50802            2  \n",
       "51109            2  \n",
       "3972             0  \n",
       "12236            0  \n",
       "13041            0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATASET_PATH)\n",
    "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-23T09:34:36.147605Z",
     "iopub.status.busy": "2020-10-23T09:34:36.147459Z",
     "iopub.status.idle": "2020-10-23T09:34:36.150759Z",
     "shell.execute_reply": "2020-10-23T09:34:36.150104Z",
     "shell.execute_reply.started": "2020-10-23T09:34:36.147585Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_words(text):\n",
    "    try:\n",
    "        return len(text.split())\n",
    "    except:\n",
    "        print(text)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-23T09:34:36.151864Z",
     "iopub.status.busy": "2020-10-23T09:34:36.151606Z",
     "iopub.status.idle": "2020-10-23T09:34:36.158324Z",
     "shell.execute_reply": "2020-10-23T09:34:36.157681Z",
     "shell.execute_reply.started": "2020-10-23T09:34:36.151817Z"
    }
   },
   "outputs": [],
   "source": [
    "def change_rel(num):\n",
    "    if num == 2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-23T09:34:36.159208Z",
     "iopub.status.busy": "2020-10-23T09:34:36.159012Z",
     "iopub.status.idle": "2020-10-23T09:34:49.687550Z",
     "shell.execute_reply": "2020-10-23T09:34:49.686780Z",
     "shell.execute_reply.started": "2020-10-23T09:34:36.159187Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = []\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = str(text)\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
    "#    text = re.sub(r'\\W+', '', text)\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text\n",
    "    return text\n",
    "df['content'] = df['content'].apply(clean_text)\n",
    "df['content'] = df['content'].str.replace('\\d+', '')\n",
    "df['Reliability'] = df['Reliability'].apply(change_rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-23T09:34:49.689814Z",
     "iopub.status.busy": "2020-10-23T09:34:49.689595Z",
     "iopub.status.idle": "2020-10-23T09:34:51.055397Z",
     "shell.execute_reply": "2020-10-23T09:34:51.054861Z",
     "shell.execute_reply.started": "2020-10-23T09:34:49.689791Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15183"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['content'].apply(count_words).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-23T09:34:51.056512Z",
     "iopub.status.busy": "2020-10-23T09:34:51.056359Z",
     "iopub.status.idle": "2020-10-23T09:34:51.080041Z",
     "shell.execute_reply": "2020-10-23T09:34:51.079577Z",
     "shell.execute_reply.started": "2020-10-23T09:34:51.056493Z"
    }
   },
   "outputs": [],
   "source": [
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(df['content'], df['Reliability'], test_size=0.2, stratify=df['Reliability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-23T09:34:51.080882Z",
     "iopub.status.busy": "2020-10-23T09:34:51.080739Z",
     "iopub.status.idle": "2020-10-23T09:34:51.083481Z",
     "shell.execute_reply": "2020-10-23T09:34:51.082924Z",
     "shell.execute_reply.started": "2020-10-23T09:34:51.080863Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 511\n",
    "posts = train_x.values\n",
    "categories = train_y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-23T09:34:51.084427Z",
     "iopub.status.busy": "2020-10-23T09:34:51.084267Z",
     "iopub.status.idle": "2020-10-23T09:34:51.107062Z",
     "shell.execute_reply": "2020-10-23T09:34:51.106541Z",
     "shell.execute_reply.started": "2020-10-23T09:34:51.084408Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tathagata.raha/miniconda3/envs/fastai/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1764: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1037,  6715,  2038,  2042,  2218,  2005,  1037,  2329,  3232,\n",
       "          2040,  2351,  2306,  2847,  1997,  2169,  2060,  1999,  2660, 17386,\n",
       "          2239,  4557,  2001,  2718,  2011,  1037,  2482,  1999,  9300,  2006,\n",
       "          2285,  1998,  4256,  5650,  6157,  2001,  2101,  2179,  2757,  2050,\n",
       "          4101,  2326,  1997,  7401,  1998, 15060,  2001,  2218,  2012, 10093,\n",
       "          3877, 13675, 14545, 24390,  1999, 19322,  2006,  5958, 19699,  9013,\n",
       "          2094,  4775,  2577,  2056,  2027,  2106,  2062,  1999,  1996,  2261,\n",
       "          2086,  2027,  2020,  2362,  2084,  2087,  2111,  2079,  1999,  1037,\n",
       "          6480, 10760,  3232,  2761,  2013, 19322,  2333,  2000,  9300,  2197,\n",
       "          2095,  5974,  2084,  2827,  6363,  2001,  2992,  3081,  1037,  2175,\n",
       "          4636,  2033,  3931,  2275,  2039,  2011,  2720,  4557,  2827,  4043,\n",
       "          2136, 26046,  4570, 26846,  2000,  2393,  1996,  6062,  9064,  2007,\n",
       "          2151,  5366,  3378,  2007,  4192,  2037,  4230,  2000,  1996,  2866,\n",
       "          2213,  2099,  2577,  3580, 24925, 14515,  1997,  7987,  3593, 26745,\n",
       "         15265,  4043,  2252,  2056,  2720,  4557,  2001,  1037, 10904, 27168,\n",
       "         10760,  2100,  2020,  1037,  2200,  2759,  3232,  2002,  2794,  2072,\n",
       "          2113,  2037,  2293,  2005,  2169,  2060,  2001,  5525,  5294,  5369,\n",
       "          2056,  4209,  2054,  4463,  2001,  2066,  2002,  2876,  2102,  2215,\n",
       "          7955,  2000,  2022,  6517,  5369,  2001,  1996,  4066,  1997, 14804,\n",
       "          2040,  2052,  3328,  2046,  1037,  2282,  1998,  2422,  2009,  2039,\n",
       "          2007,  2010,  3739,  2378, 15500,  2015,  2046,  2119,  6677,  2024,\n",
       "          2349,  2000,  2022,  2441,  2006,  2337,  2012, 13182,  9892,  1999,\n",
       "         18174, 14876,  7174,  2860,  4035,  2225, 13256,  2006,  9130,  2006,\n",
       "         10474,  1998,  3696,  2039,  2005,  2334,  2739, 14409,  3622,  2000,\n",
       "          2115,  3042,   102,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dict = tokenizer.encode_plus(\n",
    "                        posts[0],                      # Sentence to encode.\n",
    "                        truncation=True,\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = MAX_LENGTH,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "encoded_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-23T09:34:51.108066Z",
     "iopub.status.busy": "2020-10-23T09:34:51.107911Z",
     "iopub.status.idle": "2020-10-23T09:40:39.939345Z",
     "shell.execute_reply": "2020-10-23T09:40:39.938454Z",
     "shell.execute_reply.started": "2020-10-23T09:34:51.108046Z"
    }
   },
   "outputs": [],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in posts:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    try:\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "                            sent,                      # Sentence to encode.\n",
    "                            truncation=True,\n",
    "                            add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                            max_length = MAX_LENGTH,           # Pad & truncate all sentences.\n",
    "                            pad_to_max_length = True,\n",
    "                            return_attention_mask = True,   # Construct attn. masks.\n",
    "                            return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                       )\n",
    "    except:\n",
    "        print(sent)\n",
    "    \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-23T09:40:39.941095Z",
     "iopub.status.busy": "2020-10-23T09:40:39.940800Z",
     "iopub.status.idle": "2020-10-23T09:40:39.950378Z",
     "shell.execute_reply": "2020-10-23T09:40:39.949762Z",
     "shell.execute_reply.started": "2020-10-23T09:40:39.941054Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40,009 training samples\n",
      "5,716 validation samples\n"
     ]
    }
   ],
   "source": [
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "train_size = int(0.875 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# Divide the dataset by randomly selecting samples.\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-23T09:40:39.951343Z",
     "iopub.status.busy": "2020-10-23T09:40:39.951165Z",
     "iopub.status.idle": "2020-10-23T09:40:39.955111Z",
     "shell.execute_reply": "2020-10-23T09:40:39.954533Z",
     "shell.execute_reply.started": "2020-10-23T09:40:39.951320Z"
    }
   },
   "outputs": [],
   "source": [
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "# size of 16 or 32.\n",
    "batch_size = 8\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-23T09:40:39.955962Z",
     "iopub.status.busy": "2020-10-23T09:40:39.955761Z",
     "iopub.status.idle": "2020-10-23T09:40:51.675342Z",
     "shell.execute_reply": "2020-10-23T09:40:51.674842Z",
     "shell.execute_reply.started": "2020-10-23T09:40:39.955939Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "import torch.nn as nn\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
    "                    # You can increase this for multi-class tasks.\n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "# model = nn.DataParallel(model)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-23T09:40:51.676642Z",
     "iopub.status.busy": "2020-10-23T09:40:51.676472Z",
     "iopub.status.idle": "2020-10-23T09:40:51.684662Z",
     "shell.execute_reply": "2020-10-23T09:40:51.683967Z",
     "shell.execute_reply.started": "2020-10-23T09:40:51.676619Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (2, 768)\n",
      "classifier.bias                                                 (2,)\n"
     ]
    }
   ],
   "source": [
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-23T09:40:51.685558Z",
     "iopub.status.busy": "2020-10-23T09:40:51.685404Z",
     "iopub.status.idle": "2020-10-23T09:40:51.690526Z",
     "shell.execute_reply": "2020-10-23T09:40:51.690020Z",
     "shell.execute_reply.started": "2020-10-23T09:40:51.685539Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 5e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-23T09:40:51.691392Z",
     "iopub.status.busy": "2020-10-23T09:40:51.691239Z",
     "iopub.status.idle": "2020-10-23T09:40:51.697800Z",
     "shell.execute_reply": "2020-10-23T09:40:51.697208Z",
     "shell.execute_reply.started": "2020-10-23T09:40:51.691370Z"
    }
   },
   "outputs": [],
   "source": [
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = 4\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-23T09:40:51.698624Z",
     "iopub.status.busy": "2020-10-23T09:40:51.698461Z",
     "iopub.status.idle": "2020-10-23T09:40:51.705317Z",
     "shell.execute_reply": "2020-10-23T09:40:51.704571Z",
     "shell.execute_reply.started": "2020-10-23T09:40:51.698596Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-23T09:40:51.706110Z",
     "iopub.status.busy": "2020-10-23T09:40:51.705971Z",
     "iopub.status.idle": "2020-10-23T09:40:51.712163Z",
     "shell.execute_reply": "2020-10-23T09:40:51.711650Z",
     "shell.execute_reply.started": "2020-10-23T09:40:51.706091Z"
    }
   },
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-23T09:40:51.713112Z",
     "iopub.status.busy": "2020-10-23T09:40:51.712965Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of  5,002.    Elapsed: 0:00:12.\n",
      "  Batch    80  of  5,002.    Elapsed: 0:00:25.\n",
      "  Batch   120  of  5,002.    Elapsed: 0:00:37.\n",
      "  Batch   160  of  5,002.    Elapsed: 0:00:50.\n",
      "  Batch   200  of  5,002.    Elapsed: 0:01:02.\n",
      "  Batch   240  of  5,002.    Elapsed: 0:01:15.\n",
      "  Batch   280  of  5,002.    Elapsed: 0:01:27.\n",
      "  Batch   320  of  5,002.    Elapsed: 0:01:40.\n",
      "  Batch   360  of  5,002.    Elapsed: 0:01:52.\n",
      "  Batch   400  of  5,002.    Elapsed: 0:02:05.\n",
      "  Batch   440  of  5,002.    Elapsed: 0:02:18.\n",
      "  Batch   480  of  5,002.    Elapsed: 0:02:30.\n",
      "  Batch   520  of  5,002.    Elapsed: 0:02:43.\n",
      "  Batch   560  of  5,002.    Elapsed: 0:02:56.\n",
      "  Batch   600  of  5,002.    Elapsed: 0:03:08.\n",
      "  Batch   640  of  5,002.    Elapsed: 0:03:21.\n",
      "  Batch   680  of  5,002.    Elapsed: 0:03:34.\n",
      "  Batch   720  of  5,002.    Elapsed: 0:03:46.\n",
      "  Batch   760  of  5,002.    Elapsed: 0:03:59.\n",
      "  Batch   800  of  5,002.    Elapsed: 0:04:12.\n",
      "  Batch   840  of  5,002.    Elapsed: 0:04:25.\n",
      "  Batch   880  of  5,002.    Elapsed: 0:04:37.\n",
      "  Batch   920  of  5,002.    Elapsed: 0:04:50.\n",
      "  Batch   960  of  5,002.    Elapsed: 0:05:03.\n",
      "  Batch 1,000  of  5,002.    Elapsed: 0:05:15.\n",
      "  Batch 1,040  of  5,002.    Elapsed: 0:05:28.\n",
      "  Batch 1,080  of  5,002.    Elapsed: 0:05:41.\n",
      "  Batch 1,120  of  5,002.    Elapsed: 0:05:53.\n",
      "  Batch 1,160  of  5,002.    Elapsed: 0:06:06.\n",
      "  Batch 1,200  of  5,002.    Elapsed: 0:06:19.\n",
      "  Batch 1,240  of  5,002.    Elapsed: 0:06:31.\n",
      "  Batch 1,280  of  5,002.    Elapsed: 0:06:44.\n",
      "  Batch 1,320  of  5,002.    Elapsed: 0:06:57.\n",
      "  Batch 1,360  of  5,002.    Elapsed: 0:07:10.\n",
      "  Batch 1,400  of  5,002.    Elapsed: 0:07:22.\n",
      "  Batch 1,440  of  5,002.    Elapsed: 0:07:35.\n",
      "  Batch 1,480  of  5,002.    Elapsed: 0:07:48.\n",
      "  Batch 1,520  of  5,002.    Elapsed: 0:08:00.\n",
      "  Batch 1,560  of  5,002.    Elapsed: 0:08:13.\n",
      "  Batch 1,600  of  5,002.    Elapsed: 0:08:26.\n",
      "  Batch 1,640  of  5,002.    Elapsed: 0:08:38.\n",
      "  Batch 1,680  of  5,002.    Elapsed: 0:08:51.\n",
      "  Batch 1,720  of  5,002.    Elapsed: 0:09:04.\n",
      "  Batch 1,760  of  5,002.    Elapsed: 0:09:16.\n",
      "  Batch 1,800  of  5,002.    Elapsed: 0:09:29.\n",
      "  Batch 1,840  of  5,002.    Elapsed: 0:09:42.\n",
      "  Batch 1,880  of  5,002.    Elapsed: 0:09:55.\n",
      "  Batch 1,920  of  5,002.    Elapsed: 0:10:07.\n",
      "  Batch 1,960  of  5,002.    Elapsed: 0:10:20.\n",
      "  Batch 2,000  of  5,002.    Elapsed: 0:10:33.\n",
      "  Batch 2,040  of  5,002.    Elapsed: 0:10:45.\n",
      "  Batch 2,080  of  5,002.    Elapsed: 0:10:58.\n",
      "  Batch 2,120  of  5,002.    Elapsed: 0:11:11.\n",
      "  Batch 2,160  of  5,002.    Elapsed: 0:11:23.\n",
      "  Batch 2,200  of  5,002.    Elapsed: 0:11:36.\n",
      "  Batch 2,240  of  5,002.    Elapsed: 0:11:49.\n",
      "  Batch 2,280  of  5,002.    Elapsed: 0:12:01.\n",
      "  Batch 2,320  of  5,002.    Elapsed: 0:12:14.\n",
      "  Batch 2,360  of  5,002.    Elapsed: 0:12:27.\n",
      "  Batch 2,400  of  5,002.    Elapsed: 0:12:40.\n",
      "  Batch 2,440  of  5,002.    Elapsed: 0:12:52.\n",
      "  Batch 2,480  of  5,002.    Elapsed: 0:13:05.\n",
      "  Batch 2,520  of  5,002.    Elapsed: 0:13:18.\n",
      "  Batch 2,560  of  5,002.    Elapsed: 0:13:30.\n",
      "  Batch 2,600  of  5,002.    Elapsed: 0:13:43.\n",
      "  Batch 2,640  of  5,002.    Elapsed: 0:13:56.\n",
      "  Batch 2,680  of  5,002.    Elapsed: 0:14:08.\n",
      "  Batch 2,720  of  5,002.    Elapsed: 0:14:21.\n",
      "  Batch 2,760  of  5,002.    Elapsed: 0:14:34.\n",
      "  Batch 2,800  of  5,002.    Elapsed: 0:14:46.\n",
      "  Batch 2,840  of  5,002.    Elapsed: 0:14:59.\n",
      "  Batch 2,880  of  5,002.    Elapsed: 0:15:12.\n",
      "  Batch 2,920  of  5,002.    Elapsed: 0:15:25.\n",
      "  Batch 2,960  of  5,002.    Elapsed: 0:15:37.\n",
      "  Batch 3,000  of  5,002.    Elapsed: 0:15:50.\n",
      "  Batch 3,040  of  5,002.    Elapsed: 0:16:03.\n",
      "  Batch 3,080  of  5,002.    Elapsed: 0:16:15.\n",
      "  Batch 3,120  of  5,002.    Elapsed: 0:16:28.\n",
      "  Batch 3,160  of  5,002.    Elapsed: 0:16:41.\n",
      "  Batch 3,200  of  5,002.    Elapsed: 0:16:53.\n",
      "  Batch 3,240  of  5,002.    Elapsed: 0:17:06.\n",
      "  Batch 3,280  of  5,002.    Elapsed: 0:17:19.\n",
      "  Batch 3,320  of  5,002.    Elapsed: 0:17:32.\n",
      "  Batch 3,360  of  5,002.    Elapsed: 0:17:44.\n",
      "  Batch 3,400  of  5,002.    Elapsed: 0:17:57.\n",
      "  Batch 3,440  of  5,002.    Elapsed: 0:18:10.\n",
      "  Batch 3,480  of  5,002.    Elapsed: 0:18:22.\n",
      "  Batch 3,520  of  5,002.    Elapsed: 0:18:35.\n",
      "  Batch 3,560  of  5,002.    Elapsed: 0:18:48.\n",
      "  Batch 3,600  of  5,002.    Elapsed: 0:19:00.\n",
      "  Batch 3,640  of  5,002.    Elapsed: 0:19:13.\n",
      "  Batch 3,680  of  5,002.    Elapsed: 0:19:26.\n",
      "  Batch 3,720  of  5,002.    Elapsed: 0:19:38.\n",
      "  Batch 3,760  of  5,002.    Elapsed: 0:19:51.\n",
      "  Batch 3,800  of  5,002.    Elapsed: 0:20:04.\n",
      "  Batch 3,840  of  5,002.    Elapsed: 0:20:17.\n",
      "  Batch 3,880  of  5,002.    Elapsed: 0:20:29.\n",
      "  Batch 3,920  of  5,002.    Elapsed: 0:20:42.\n",
      "  Batch 3,960  of  5,002.    Elapsed: 0:20:55.\n",
      "  Batch 4,000  of  5,002.    Elapsed: 0:21:07.\n",
      "  Batch 4,040  of  5,002.    Elapsed: 0:21:20.\n",
      "  Batch 4,080  of  5,002.    Elapsed: 0:21:33.\n",
      "  Batch 4,120  of  5,002.    Elapsed: 0:21:45.\n",
      "  Batch 4,160  of  5,002.    Elapsed: 0:21:58.\n",
      "  Batch 4,200  of  5,002.    Elapsed: 0:22:11.\n",
      "  Batch 4,240  of  5,002.    Elapsed: 0:22:24.\n",
      "  Batch 4,280  of  5,002.    Elapsed: 0:22:36.\n",
      "  Batch 4,320  of  5,002.    Elapsed: 0:22:49.\n",
      "  Batch 4,360  of  5,002.    Elapsed: 0:23:02.\n",
      "  Batch 4,400  of  5,002.    Elapsed: 0:23:14.\n",
      "  Batch 4,440  of  5,002.    Elapsed: 0:23:27.\n",
      "  Batch 4,480  of  5,002.    Elapsed: 0:23:40.\n",
      "  Batch 4,520  of  5,002.    Elapsed: 0:23:52.\n",
      "  Batch 4,560  of  5,002.    Elapsed: 0:24:05.\n",
      "  Batch 4,600  of  5,002.    Elapsed: 0:24:18.\n",
      "  Batch 4,640  of  5,002.    Elapsed: 0:24:30.\n",
      "  Batch 4,680  of  5,002.    Elapsed: 0:24:43.\n",
      "  Batch 4,720  of  5,002.    Elapsed: 0:24:56.\n",
      "  Batch 4,760  of  5,002.    Elapsed: 0:25:09.\n",
      "  Batch 4,800  of  5,002.    Elapsed: 0:25:21.\n",
      "  Batch 4,840  of  5,002.    Elapsed: 0:25:34.\n",
      "  Batch 4,880  of  5,002.    Elapsed: 0:25:47.\n",
      "  Batch 4,920  of  5,002.    Elapsed: 0:25:59.\n",
      "  Batch 4,960  of  5,002.    Elapsed: 0:26:12.\n",
      "  Batch 5,000  of  5,002.    Elapsed: 0:26:25.\n",
      "\n",
      "  Average training loss: 0.54\n",
      "  Training epcoh took: 0:26:25\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.78\n",
      "  Validation Loss: 0.54\n",
      "  Validation took: 0:01:14\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of  5,002.    Elapsed: 0:00:13.\n",
      "  Batch    80  of  5,002.    Elapsed: 0:00:25.\n",
      "  Batch   120  of  5,002.    Elapsed: 0:00:38.\n",
      "  Batch   160  of  5,002.    Elapsed: 0:00:51.\n",
      "  Batch   200  of  5,002.    Elapsed: 0:01:04.\n",
      "  Batch   240  of  5,002.    Elapsed: 0:01:16.\n",
      "  Batch   280  of  5,002.    Elapsed: 0:01:29.\n",
      "  Batch   320  of  5,002.    Elapsed: 0:01:42.\n",
      "  Batch   360  of  5,002.    Elapsed: 0:01:54.\n",
      "  Batch   400  of  5,002.    Elapsed: 0:02:07.\n",
      "  Batch   440  of  5,002.    Elapsed: 0:02:20.\n",
      "  Batch   480  of  5,002.    Elapsed: 0:02:32.\n",
      "  Batch   520  of  5,002.    Elapsed: 0:02:45.\n",
      "  Batch   560  of  5,002.    Elapsed: 0:02:58.\n",
      "  Batch   600  of  5,002.    Elapsed: 0:03:10.\n",
      "  Batch   640  of  5,002.    Elapsed: 0:03:23.\n",
      "  Batch   680  of  5,002.    Elapsed: 0:03:36.\n",
      "  Batch   720  of  5,002.    Elapsed: 0:03:48.\n",
      "  Batch   760  of  5,002.    Elapsed: 0:04:01.\n",
      "  Batch   800  of  5,002.    Elapsed: 0:04:14.\n",
      "  Batch   840  of  5,002.    Elapsed: 0:04:27.\n",
      "  Batch   880  of  5,002.    Elapsed: 0:04:39.\n",
      "  Batch   920  of  5,002.    Elapsed: 0:04:52.\n",
      "  Batch   960  of  5,002.    Elapsed: 0:05:05.\n",
      "  Batch 1,000  of  5,002.    Elapsed: 0:05:17.\n",
      "  Batch 1,040  of  5,002.    Elapsed: 0:05:30.\n",
      "  Batch 1,080  of  5,002.    Elapsed: 0:05:43.\n",
      "  Batch 1,120  of  5,002.    Elapsed: 0:05:55.\n",
      "  Batch 1,160  of  5,002.    Elapsed: 0:06:08.\n",
      "  Batch 1,200  of  5,002.    Elapsed: 0:06:21.\n",
      "  Batch 1,240  of  5,002.    Elapsed: 0:06:33.\n",
      "  Batch 1,280  of  5,002.    Elapsed: 0:06:46.\n",
      "  Batch 1,320  of  5,002.    Elapsed: 0:06:59.\n",
      "  Batch 1,360  of  5,002.    Elapsed: 0:07:11.\n",
      "  Batch 1,400  of  5,002.    Elapsed: 0:07:24.\n",
      "  Batch 1,440  of  5,002.    Elapsed: 0:07:37.\n",
      "  Batch 1,480  of  5,002.    Elapsed: 0:07:49.\n",
      "  Batch 1,520  of  5,002.    Elapsed: 0:08:02.\n",
      "  Batch 1,560  of  5,002.    Elapsed: 0:08:15.\n",
      "  Batch 1,600  of  5,002.    Elapsed: 0:08:28.\n",
      "  Batch 1,640  of  5,002.    Elapsed: 0:08:40.\n",
      "  Batch 1,680  of  5,002.    Elapsed: 0:08:53.\n",
      "  Batch 1,720  of  5,002.    Elapsed: 0:09:06.\n",
      "  Batch 1,760  of  5,002.    Elapsed: 0:09:18.\n",
      "  Batch 1,800  of  5,002.    Elapsed: 0:09:31.\n",
      "  Batch 1,840  of  5,002.    Elapsed: 0:09:44.\n",
      "  Batch 1,880  of  5,002.    Elapsed: 0:09:56.\n",
      "  Batch 1,920  of  5,002.    Elapsed: 0:10:09.\n",
      "  Batch 1,960  of  5,002.    Elapsed: 0:10:22.\n",
      "  Batch 2,000  of  5,002.    Elapsed: 0:10:34.\n",
      "  Batch 2,040  of  5,002.    Elapsed: 0:10:47.\n",
      "  Batch 2,080  of  5,002.    Elapsed: 0:11:00.\n",
      "  Batch 2,120  of  5,002.    Elapsed: 0:11:13.\n",
      "  Batch 2,160  of  5,002.    Elapsed: 0:11:25.\n",
      "  Batch 2,200  of  5,002.    Elapsed: 0:11:38.\n",
      "  Batch 2,240  of  5,002.    Elapsed: 0:11:51.\n",
      "  Batch 2,280  of  5,002.    Elapsed: 0:12:03.\n",
      "  Batch 2,320  of  5,002.    Elapsed: 0:12:16.\n",
      "  Batch 2,360  of  5,002.    Elapsed: 0:12:29.\n",
      "  Batch 2,400  of  5,002.    Elapsed: 0:12:41.\n",
      "  Batch 2,440  of  5,002.    Elapsed: 0:12:54.\n",
      "  Batch 2,480  of  5,002.    Elapsed: 0:13:07.\n",
      "  Batch 2,520  of  5,002.    Elapsed: 0:13:19.\n",
      "  Batch 2,560  of  5,002.    Elapsed: 0:13:32.\n",
      "  Batch 2,600  of  5,002.    Elapsed: 0:13:45.\n",
      "  Batch 2,640  of  5,002.    Elapsed: 0:13:58.\n",
      "  Batch 2,680  of  5,002.    Elapsed: 0:14:10.\n",
      "  Batch 2,720  of  5,002.    Elapsed: 0:14:23.\n",
      "  Batch 2,760  of  5,002.    Elapsed: 0:14:36.\n",
      "  Batch 2,800  of  5,002.    Elapsed: 0:14:48.\n",
      "  Batch 2,840  of  5,002.    Elapsed: 0:15:01.\n",
      "  Batch 2,880  of  5,002.    Elapsed: 0:15:14.\n",
      "  Batch 2,920  of  5,002.    Elapsed: 0:15:26.\n",
      "  Batch 2,960  of  5,002.    Elapsed: 0:15:39.\n",
      "  Batch 3,000  of  5,002.    Elapsed: 0:15:52.\n",
      "  Batch 3,040  of  5,002.    Elapsed: 0:16:04.\n",
      "  Batch 3,080  of  5,002.    Elapsed: 0:16:17.\n",
      "  Batch 3,120  of  5,002.    Elapsed: 0:16:30.\n",
      "  Batch 3,160  of  5,002.    Elapsed: 0:16:42.\n",
      "  Batch 3,200  of  5,002.    Elapsed: 0:16:55.\n",
      "  Batch 3,240  of  5,002.    Elapsed: 0:17:08.\n",
      "  Batch 3,280  of  5,002.    Elapsed: 0:17:21.\n",
      "  Batch 3,320  of  5,002.    Elapsed: 0:17:33.\n",
      "  Batch 3,360  of  5,002.    Elapsed: 0:17:46.\n",
      "  Batch 3,400  of  5,002.    Elapsed: 0:17:59.\n",
      "  Batch 3,440  of  5,002.    Elapsed: 0:18:11.\n",
      "  Batch 3,480  of  5,002.    Elapsed: 0:18:24.\n",
      "  Batch 3,520  of  5,002.    Elapsed: 0:18:37.\n",
      "  Batch 3,560  of  5,002.    Elapsed: 0:18:49.\n",
      "  Batch 3,600  of  5,002.    Elapsed: 0:19:02.\n",
      "  Batch 3,640  of  5,002.    Elapsed: 0:19:15.\n",
      "  Batch 3,680  of  5,002.    Elapsed: 0:19:27.\n",
      "  Batch 3,720  of  5,002.    Elapsed: 0:19:40.\n",
      "  Batch 3,760  of  5,002.    Elapsed: 0:19:53.\n",
      "  Batch 3,800  of  5,002.    Elapsed: 0:20:06.\n",
      "  Batch 3,840  of  5,002.    Elapsed: 0:20:18.\n",
      "  Batch 3,880  of  5,002.    Elapsed: 0:20:31.\n",
      "  Batch 3,920  of  5,002.    Elapsed: 0:20:44.\n",
      "  Batch 3,960  of  5,002.    Elapsed: 0:20:56.\n",
      "  Batch 4,000  of  5,002.    Elapsed: 0:21:09.\n",
      "  Batch 4,040  of  5,002.    Elapsed: 0:21:22.\n",
      "  Batch 4,080  of  5,002.    Elapsed: 0:21:34.\n",
      "  Batch 4,120  of  5,002.    Elapsed: 0:21:47.\n",
      "  Batch 4,160  of  5,002.    Elapsed: 0:22:00.\n",
      "  Batch 4,200  of  5,002.    Elapsed: 0:22:13.\n",
      "  Batch 4,240  of  5,002.    Elapsed: 0:22:25.\n",
      "  Batch 4,280  of  5,002.    Elapsed: 0:22:38.\n",
      "  Batch 4,320  of  5,002.    Elapsed: 0:22:51.\n",
      "  Batch 4,360  of  5,002.    Elapsed: 0:23:03.\n",
      "  Batch 4,400  of  5,002.    Elapsed: 0:23:16.\n",
      "  Batch 4,440  of  5,002.    Elapsed: 0:23:29.\n",
      "  Batch 4,480  of  5,002.    Elapsed: 0:23:41.\n",
      "  Batch 4,520  of  5,002.    Elapsed: 0:23:54.\n",
      "  Batch 4,560  of  5,002.    Elapsed: 0:24:07.\n",
      "  Batch 4,600  of  5,002.    Elapsed: 0:24:19.\n",
      "  Batch 4,640  of  5,002.    Elapsed: 0:24:32.\n",
      "  Batch 4,680  of  5,002.    Elapsed: 0:24:45.\n",
      "  Batch 4,720  of  5,002.    Elapsed: 0:24:58.\n",
      "  Batch 4,760  of  5,002.    Elapsed: 0:25:10.\n",
      "  Batch 4,800  of  5,002.    Elapsed: 0:25:23.\n",
      "  Batch 4,840  of  5,002.    Elapsed: 0:25:36.\n",
      "  Batch 4,880  of  5,002.    Elapsed: 0:25:48.\n",
      "  Batch 4,920  of  5,002.    Elapsed: 0:26:01.\n",
      "  Batch 4,960  of  5,002.    Elapsed: 0:26:14.\n",
      "  Batch 5,000  of  5,002.    Elapsed: 0:26:26.\n",
      "\n",
      "  Average training loss: 0.53\n",
      "  Training epcoh took: 0:26:27\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.78\n",
      "  Validation Loss: 0.53\n",
      "  Validation took: 0:01:14\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " no\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of  5,002.    Elapsed: 0:00:12.\n",
      "  Batch    80  of  5,002.    Elapsed: 0:00:25.\n",
      "  Batch   120  of  5,002.    Elapsed: 0:00:37.\n",
      "  Batch   160  of  5,002.    Elapsed: 0:00:49.\n",
      "  Batch   200  of  5,002.    Elapsed: 0:01:02.\n",
      "  Batch   240  of  5,002.    Elapsed: 0:01:14.\n",
      "  Batch   280  of  5,002.    Elapsed: 0:01:27.\n",
      "  Batch   320  of  5,002.    Elapsed: 0:01:40.\n",
      "  Batch   360  of  5,002.    Elapsed: 0:01:52.\n",
      "  Batch   400  of  5,002.    Elapsed: 0:02:05.\n",
      "  Batch   440  of  5,002.    Elapsed: 0:02:18.\n",
      "  Batch   480  of  5,002.    Elapsed: 0:02:30.\n",
      "  Batch   520  of  5,002.    Elapsed: 0:02:43.\n",
      "  Batch   560  of  5,002.    Elapsed: 0:02:56.\n",
      "  Batch   600  of  5,002.    Elapsed: 0:03:08.\n",
      "  Batch   640  of  5,002.    Elapsed: 0:03:21.\n",
      "  Batch   680  of  5,002.    Elapsed: 0:03:34.\n",
      "  Batch   720  of  5,002.    Elapsed: 0:03:46.\n",
      "  Batch   760  of  5,002.    Elapsed: 0:03:59.\n",
      "  Batch   800  of  5,002.    Elapsed: 0:04:12.\n",
      "  Batch   840  of  5,002.    Elapsed: 0:04:24.\n",
      "  Batch   880  of  5,002.    Elapsed: 0:04:37.\n",
      "  Batch   920  of  5,002.    Elapsed: 0:04:50.\n",
      "  Batch   960  of  5,002.    Elapsed: 0:05:03.\n",
      "  Batch 1,000  of  5,002.    Elapsed: 0:05:15.\n",
      "  Batch 1,040  of  5,002.    Elapsed: 0:05:28.\n",
      "  Batch 1,080  of  5,002.    Elapsed: 0:05:41.\n",
      "  Batch 1,120  of  5,002.    Elapsed: 0:05:53.\n",
      "  Batch 1,160  of  5,002.    Elapsed: 0:06:06.\n",
      "  Batch 1,200  of  5,002.    Elapsed: 0:06:19.\n",
      "  Batch 1,240  of  5,002.    Elapsed: 0:06:31.\n",
      "  Batch 1,280  of  5,002.    Elapsed: 0:06:44.\n",
      "  Batch 1,320  of  5,002.    Elapsed: 0:06:57.\n",
      "  Batch 1,360  of  5,002.    Elapsed: 0:07:09.\n",
      "  Batch 1,400  of  5,002.    Elapsed: 0:07:22.\n",
      "  Batch 1,440  of  5,002.    Elapsed: 0:07:35.\n",
      "  Batch 1,480  of  5,002.    Elapsed: 0:07:48.\n",
      "  Batch 1,520  of  5,002.    Elapsed: 0:08:00.\n",
      "  Batch 1,560  of  5,002.    Elapsed: 0:08:13.\n",
      "  Batch 1,600  of  5,002.    Elapsed: 0:08:26.\n",
      "  Batch 1,640  of  5,002.    Elapsed: 0:08:38.\n",
      "  Batch 1,680  of  5,002.    Elapsed: 0:08:51.\n",
      "  Batch 1,720  of  5,002.    Elapsed: 0:09:04.\n",
      "  Batch 1,760  of  5,002.    Elapsed: 0:09:16.\n",
      "  Batch 1,800  of  5,002.    Elapsed: 0:09:29.\n",
      "  Batch 1,840  of  5,002.    Elapsed: 0:09:42.\n",
      "  Batch 1,880  of  5,002.    Elapsed: 0:09:55.\n",
      "  Batch 1,920  of  5,002.    Elapsed: 0:10:07.\n",
      "  Batch 1,960  of  5,002.    Elapsed: 0:10:20.\n",
      "  Batch 2,000  of  5,002.    Elapsed: 0:10:33.\n",
      "  Batch 2,040  of  5,002.    Elapsed: 0:10:45.\n",
      "  Batch 2,080  of  5,002.    Elapsed: 0:10:58.\n",
      "  Batch 2,120  of  5,002.    Elapsed: 0:11:11.\n",
      "  Batch 2,160  of  5,002.    Elapsed: 0:11:23.\n",
      "  Batch 2,200  of  5,002.    Elapsed: 0:11:36.\n",
      "  Batch 2,240  of  5,002.    Elapsed: 0:11:49.\n",
      "  Batch 2,280  of  5,002.    Elapsed: 0:12:02.\n",
      "  Batch 2,320  of  5,002.    Elapsed: 0:12:14.\n",
      "  Batch 2,360  of  5,002.    Elapsed: 0:12:27.\n",
      "  Batch 2,400  of  5,002.    Elapsed: 0:12:40.\n",
      "  Batch 2,440  of  5,002.    Elapsed: 0:12:52.\n",
      "  Batch 2,480  of  5,002.    Elapsed: 0:13:05.\n",
      "  Batch 2,520  of  5,002.    Elapsed: 0:13:18.\n",
      "  Batch 2,560  of  5,002.    Elapsed: 0:13:30.\n",
      "  Batch 2,600  of  5,002.    Elapsed: 0:13:43.\n",
      "  Batch 2,640  of  5,002.    Elapsed: 0:13:56.\n",
      "  Batch 2,680  of  5,002.    Elapsed: 0:14:09.\n",
      "  Batch 2,720  of  5,002.    Elapsed: 0:14:21.\n",
      "  Batch 2,760  of  5,002.    Elapsed: 0:14:34.\n",
      "  Batch 2,800  of  5,002.    Elapsed: 0:14:47.\n",
      "  Batch 2,840  of  5,002.    Elapsed: 0:14:59.\n",
      "  Batch 2,880  of  5,002.    Elapsed: 0:15:12.\n",
      "  Batch 2,920  of  5,002.    Elapsed: 0:15:25.\n",
      "  Batch 2,960  of  5,002.    Elapsed: 0:15:38.\n",
      "  Batch 3,000  of  5,002.    Elapsed: 0:15:50.\n",
      "  Batch 3,040  of  5,002.    Elapsed: 0:16:03.\n",
      "  Batch 3,080  of  5,002.    Elapsed: 0:16:16.\n",
      "  Batch 3,120  of  5,002.    Elapsed: 0:16:28.\n",
      "  Batch 3,160  of  5,002.    Elapsed: 0:16:41.\n",
      "  Batch 3,200  of  5,002.    Elapsed: 0:16:54.\n",
      "  Batch 3,240  of  5,002.    Elapsed: 0:17:07.\n",
      "  Batch 3,280  of  5,002.    Elapsed: 0:17:19.\n",
      "  Batch 3,320  of  5,002.    Elapsed: 0:17:32.\n",
      "  Batch 3,360  of  5,002.    Elapsed: 0:17:45.\n",
      "  Batch 3,400  of  5,002.    Elapsed: 0:17:57.\n",
      "  Batch 3,440  of  5,002.    Elapsed: 0:18:10.\n",
      "  Batch 3,480  of  5,002.    Elapsed: 0:18:23.\n",
      "  Batch 3,520  of  5,002.    Elapsed: 0:18:35.\n",
      "  Batch 3,560  of  5,002.    Elapsed: 0:18:48.\n",
      "  Batch 3,600  of  5,002.    Elapsed: 0:19:01.\n",
      "  Batch 3,640  of  5,002.    Elapsed: 0:19:14.\n",
      "  Batch 3,680  of  5,002.    Elapsed: 0:19:26.\n",
      "  Batch 3,720  of  5,002.    Elapsed: 0:19:39.\n",
      "  Batch 3,760  of  5,002.    Elapsed: 0:19:52.\n",
      "  Batch 3,800  of  5,002.    Elapsed: 0:20:04.\n",
      "  Batch 3,840  of  5,002.    Elapsed: 0:20:17.\n",
      "  Batch 3,880  of  5,002.    Elapsed: 0:20:30.\n",
      "  Batch 3,920  of  5,002.    Elapsed: 0:20:42.\n",
      "  Batch 3,960  of  5,002.    Elapsed: 0:20:55.\n",
      "  Batch 4,000  of  5,002.    Elapsed: 0:21:08.\n",
      "  Batch 4,040  of  5,002.    Elapsed: 0:21:21.\n",
      "  Batch 4,080  of  5,002.    Elapsed: 0:21:33.\n",
      "  Batch 4,120  of  5,002.    Elapsed: 0:21:46.\n",
      "  Batch 4,160  of  5,002.    Elapsed: 0:21:59.\n",
      "  Batch 4,200  of  5,002.    Elapsed: 0:22:11.\n",
      "  Batch 4,240  of  5,002.    Elapsed: 0:22:24.\n",
      "  Batch 4,280  of  5,002.    Elapsed: 0:22:37.\n",
      "  Batch 4,320  of  5,002.    Elapsed: 0:22:50.\n",
      "  Batch 4,360  of  5,002.    Elapsed: 0:23:02.\n",
      "  Batch 4,400  of  5,002.    Elapsed: 0:23:15.\n",
      "  Batch 4,440  of  5,002.    Elapsed: 0:23:28.\n",
      "  Batch 4,480  of  5,002.    Elapsed: 0:23:40.\n",
      "  Batch 4,520  of  5,002.    Elapsed: 0:23:53.\n",
      "  Batch 4,560  of  5,002.    Elapsed: 0:24:06.\n",
      "  Batch 4,600  of  5,002.    Elapsed: 0:24:19.\n",
      "  Batch 4,640  of  5,002.    Elapsed: 0:24:31.\n",
      "  Batch 4,680  of  5,002.    Elapsed: 0:24:44.\n",
      "  Batch 4,720  of  5,002.    Elapsed: 0:24:57.\n",
      "  Batch 4,760  of  5,002.    Elapsed: 0:25:09.\n",
      "  Batch 4,800  of  5,002.    Elapsed: 0:25:22.\n",
      "  Batch 4,840  of  5,002.    Elapsed: 0:25:35.\n",
      "  Batch 4,880  of  5,002.    Elapsed: 0:25:47.\n",
      "  Batch 4,920  of  5,002.    Elapsed: 0:26:00.\n",
      "  Batch 4,960  of  5,002.    Elapsed: 0:26:13.\n",
      "  Batch 5,000  of  5,002.    Elapsed: 0:26:26.\n",
      "\n",
      "  Average training loss: 0.53\n",
      "  Training epcoh took: 0:26:26\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.78\n",
      "  Validation Loss: 0.53\n",
      "  Validation took: 0:01:14\n"
     ]
    }
   ],
   "source": [
    "seed_val = 42\n",
    "torch.cuda.empty_cache()\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# We'll store a number of quantities such as training and validation loss, \n",
    "# validation accuracy, and timings.\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        # It returns different numbers of parameters depending on what arguments\n",
    "        # arge given and what flags are set. For our useage here, it returns\n",
    "        # the loss (because we provided labels) and the \"logits\"--the model\n",
    "        # outputs prior to activation.\n",
    "        loss, logits = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "#         print(loss)\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "            # values prior to applying an activation function like the softmax.\n",
    "            (loss, logits) = model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "            \n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "        \n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "    if epoch_i >= 1:\n",
    "        inp = input()\n",
    "        if inp.startswith('y'):\n",
    "            break\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
